{"cells":[{"attachments":{},"cell_type":"markdown","id":"e80e0507-063e-465c-9bb4-bd58e6eb0617","metadata":{"language":"sql"},"source":"## Step 1: Create table"},{"cell_type":"code","execution_count":null,"id":"6d886f2a-25bd-43eb-b497-9cb9e7f15d60","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\nCREATE TABLE `farfetch_listings` (\n  `brand_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\n  `gender` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\n  `image_cutout_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\n  `image_model_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\n  `price` decimal(10,2) DEFAULT NULL,\n  `short_description` text CHARACTER SET utf8 COLLATE utf8_general_ci,\n  SORT KEY `price` (`price`),\n  FULLTEXT KEY `description_fulltext` (`short_description`)\n)"},{"cell_type":"code","execution_count":null,"id":"83b5fa7d-261e-485a-a4d7-194fd44bd73d","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\nshow tables;"},{"attachments":{},"cell_type":"markdown","id":"b841aa8d-070f-43fd-b181-5ba9422cf843","metadata":{"language":"sql"},"source":"## Step 2: Ingest data from S3"},{"cell_type":"code","execution_count":null,"id":"f773c6e6-7dc1-41d2-b12f-553915cf5d24","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\n-- since the bucket is open, you can leave the credentials clause as it is\ncreate or replace pipeline `farfetch_pipeline` as\nload data S3 's3://style-snatcher-demo/farfetch_listings.csv'\nconfig '{\"region\":\"us-west-1\"}'\ncredentials '{\"aws_access_key_id\": \"\",\n            \"aws_secret_access_key\": \"\"}'\nskip duplicate key errors\ninto table `farfetch_listings`\nformat csv\nfields terminated by ','\nlines terminated by '\\n';"},{"cell_type":"code","execution_count":null,"id":"458c2335-9721-4ad1-957f-a83dc728a862","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\nstart pipeline farfetch_pipeline;"},{"cell_type":"code","execution_count":null,"id":"4ae240ec-c2e5-4b06-994e-400c3c444a9d","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\nselect DATABASE_NAME, PIPELINE_NAME, BATCH_ID, BATCH_STATE, START_TIME, ROWS_STREAMED, ROWS_PER_SEC\nfrom information_schema.PIPELINES_BATCHES_SUMMARY"},{"cell_type":"code","execution_count":null,"id":"d87d35a1-eb83-47d6-b8cc-4a2644b2a6e2","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\nselect * from farfetch_listings limit 3;"},{"cell_type":"markdown","id":"83c7f711-2727-4f32-80eb-8c8c6c646ddc","metadata":{"language":"python"},"source":"## Step 3: Embed the images"},{"cell_type":"code","execution_count":null,"id":"aa08bf23-276e-4e8e-8146-0e3668043fc9","metadata":{"language":"python","trusted":true},"outputs":[],"source":"pip install fashion-clip"},{"cell_type":"code","execution_count":null,"id":"90c56d26-257b-4261-aafd-de8330f995a7","metadata":{"language":"python","trusted":true},"outputs":[],"source":"from fashion_clip.fashion_clip import FashionCLIP\nimport pandas as pd\nimport sqlalchemy as sa\nimport json"},{"cell_type":"code","execution_count":null,"id":"c50e0657-c16d-4081-ad40-0a16e707fc82","metadata":{"language":"python","trusted":true},"outputs":[],"source":"fclip = FashionCLIP('fashion-clip')"},{"cell_type":"code","execution_count":null,"id":"8f7ab018-1d65-4e82-8543-f5accf4d1377","metadata":{"language":"python","trusted":true},"outputs":[],"source":"def safe_encode_images(fclip, model_image_url, cutout_image_url):\n    try:\n        # Attempt to encode both model and cutout images\n        model_embedding = fclip.encode_images([model_image_url], batch_size=30)\n        cutout_embedding = fclip.encode_images([cutout_image_url], batch_size=30)\n        return model_embedding, cutout_embedding\n    except Exception as e:\n        print(f\"Error encoding images: Model URL: {model_image_url}, CutOut URL: {cutout_image_url}. Error: {e}\")\n        return None, None"},{"cell_type":"code","execution_count":null,"id":"69f87369-0a28-4b66-977a-0788b2099dc8","metadata":{"language":"python","trusted":true},"outputs":[],"source":"engine = sa.create_engine(connection_url)\nconn = engine.connect()\nprint(\"Connected to SingleStore!\")"},{"attachments":{},"cell_type":"markdown","id":"d154d407-8052-46bf-bd94-9eca1f65fbac","metadata":{"language":"python"},"source":"Read data from `farfetch_listings` table into pandas dataframe."},{"cell_type":"code","execution_count":null,"id":"2bb9d800-18b6-4ce2-b859-c2af077872bd","metadata":{"language":"python","trusted":true},"outputs":[],"source":"query = sa.text('''SELECT * FROM farfetch_listings;''')\ndf = pd.read_sql(query, con=conn)"},{"cell_type":"code","execution_count":null,"id":"7db4c3b0-e5c7-47db-95fd-07e1428c916b","metadata":{"language":"python","trusted":true},"outputs":[],"source":"df.to_sql('farfetch_listings', con=conn, if_exists='append', index=False)"},{"attachments":{},"cell_type":"markdown","id":"25397c92-99c1-44f1-a7d1-c97ca9afa5cf","metadata":{"language":"python"},"source":"Each product has a model image and a cutout image. We will generate embeddings for both images."},{"cell_type":"code","execution_count":null,"id":"38e2d0da-c253-4c2a-ae63-bda3588f8f98","metadata":{"language":"python","trusted":true},"outputs":[],"source":"for index, row in df.iloc[2:10].iterrows():\n    # model_image_url, cutout_image_url = row['image_model_url'], row['image_cutout_url']\n    model_embedding, cutout_embedding = safe_encode_images(fclip, row['image_model_url'], row['image_cutout_url'])\n    \n    if model_embedding is not None and cutout_embedding is not None:\n        model_embedding_str = '[' + ','.join(map(str, model_embedding.flatten().tolist())) + ']'\n        cutout_embedding_str = '[' + ','.join(map(str, cutout_embedding.flatten().tolist())) + ']'\n\n        df.at[index, 'model_embedding'] = json.dumps(model_embedding_str)\n        df.at[index, 'cutout_embedding'] = json.dumps(cutout_embedding_str)        "},{"cell_type":"markdown","id":"ae31874b-8d0d-48ec-b59f-a06cee02300d","metadata":{"language":"python"},"source":"## Step 4: Add e columns to table to store the embeddings"},{"cell_type":"code","execution_count":null,"id":"789b3a54-0766-47b4-9236-5862c29d3676","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\nALTER TABLE farfetch_listings ADD COLUMN `model_embedding` vector(512, F32);\nALTER TABLE farfetch_listings ADD COLUMN `cutout_embedding` vector(512, F32);"},{"cell_type":"code","execution_count":null,"id":"60717bdd-24bd-4ba2-8688-e5e6a1bec29b","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\n# export df to a temp table\ndf.to_sql('temp', con=conn, if_exists='replace', index=False)"},{"cell_type":"code","execution_count":null,"id":"6bf69516-d201-4b67-a9f7-cb0295f15dcb","metadata":{"language":"python","trusted":true},"outputs":[],"source":"%%sql\n# join the embeddings columns onto our table\nUPDATE farfetch_listings\nJOIN temp\nON farfetch_listings.image_cutout_url = temp.image_cutout_url\nSET farfetch_listings.model_embedding = temp.model_embedding,\n    farfetch_listings.cutout_embedding = temp.cutout_embedding;"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"42f693d5-0384-4603-a767-462840795288","defaultDatabase":""}},"nbformat":4,"nbformat_minor":5}